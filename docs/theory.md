# Теория рекомендательных систем

## I. Обзор. 

**Рекомендательные системы**  
- класс алгоритмов, предназначенных для предсказания предпочтений пользователей.  

**Зачем нужны RS**
- 30-50 % дохода Netflix/Spotify приходит из-за рекомендаций.
- Пользователь не ищет - ему подбирают → вырастает вовлечение и удержание.
  
**Цель рекомендации**  
- предсказать, какие items понравятся пользователю, опираясь на явный и/или неявный фидбек.

**Основные задачи**
- предсказание рейтинга (rating prediction) и ранжирование (top‑N recommendation). ((*В проекте фокус на top‑N задачах с implicit сигналами, но рассматриваются и классы моделей для explicit рейтингов.*))  

**Ключевые понятия**
- Пользователь - user
- Предмет рекомендаций - item
- Взаимодействие представляется матрицей R size |U|×|I|.
- Explicit фидбек - числовые рейтинги.
- Implicit фидбек - клики, просмотры, покупки, преобразуемые в бинарные метки.
- Top‑N pipeline часто состоит из двух этапов: кандидатная генерация (recall) и точное ранжирование (ranking).
  
## II. Формализуем задачу
**Дано:**
- U - множество пользователей, |U| = N
- I - множество item-ов, |I| = M
- Интеракции R = {r_ui} - рейтинги, просмотры, клики (explicit / implicit).

**Цель:**
- для каждого **u** построить ранжированный список Top-K item-ов, которых он ещё не видел.
  
## III. Виды рекомендательных систем:
![Виды рекомендательных систем.](https://github.com/Aliaksandr-Borsuk/Recommender_Systems_project/blob/main/pictures/Types%20of%20recommendation%20systems.jpg)  

## 1 Неперсонализированные (Non-personalized) рекомендации 
**(Most-popular)Коротко:**
- одинаковый набор рекомендаций для всех пользователей на основе глобальных сигналов.

**Когда использовать**
- Cold‑start и стартовые экраны.
- Редакционные и промо‑блоки.
- Базовый baseline и запасной путь при сбое персонализации.

**Основные типы**
- Популярность - топ по суммарным взаимодействиям.
- Тренды - ранжирование по росту активности.
- Категория‑топы - топы внутри разделов каталога.
- Редакционные списки - ручные подборки.

**Реализация кратко**
- Агрегируем события за окна 1/7/30 дней, используем взвешивание по времени для свежести.
- Храним в базе с периодическим обновением top‑lists для быстрой выдачи .
- Обработка новых айтемов через cold‑start bucket или выделенные exploration‑слоты.

**Bandit‑алгоритмы (коротко)**
- ищут trade-off(компромисс «изучение - использование»)
  
**Назначение:**
- баланс exploration/exploitation для global‑слотов, повышение шансов новых айтемов и оптимизация онлайн‑метрик.

**Основные простые алгоритмы:** 
- Epsilon‑Greedy (baseline), UCB (неопределённость), Thompson Sampling (байесовский подход).

## 2 Персонализированные (Personalized) рекомендации 
### 2.1 Контентная фильтрация (Content-based)
- **Идея**: Рекомендации на основе характеристик items(жанры, TF-IDF описания, год), users(возраст, любимые жанры).
- **Методы**: TF-IDF, word2vec, feature engineering

### 2.2 Коллаборативная фильтрация (Collaborative Filtering)
- **Идея**: Похожие пользователи предпочитают похожие items

#### **2.2.1 Memory-based подходы** 
- **Идея**:агрегировать извнстные рейтинги для предсказания неизвестного рейтинга  $r_{ui}$

##### **UserKNN**
- Рекомендация = средневзвешенная оценка k наиболее похожих пользователей  
**Преимущества**:  
- Простота интерпретации
- Быстрое обновление при новых данных  
**Недостатки**:
- Проблема разреженности данных
- Медленный инференс для новых пользователей  

##### **ItemKNN**
- Рекомендация = средневзвешенная оценка k наиболее похожих items  

**Преимущества**:  
- Стабильность (количество items обычно постоянно)
- Быстрый инференс после предвычисления 

#### **2.2.2 Model-based подходы** 

#### **Matrix Factorization подходы:**

##### **SVD (Singular Value Decomposition)**
- Разложение матрицы оценок R ≈ U × Σ × Vᵀ
- Latent factors: пользователи и items в одном пространстве

##### **ALS (Alternating Least Squares)**
- Оптимизация поочередно пользовательских и item факторов
- Эффективно для implicit feedback

#### **Linear Models:**

##### **EASE (Embarrassingly Shallow Autoencoders)**
- Closed-form решение для обучения
- Диагональное ограничение весов
- Высокая точность при простоте

##### **SLIM (Sparse Linear Methods)**
- Разреженные линейные комбинации
- L1-регуляризация для sparsity

#### **Нейро подходы:**

##### **NCF (Neural Collaborative Filtering)**
- MLP поверх эмбеддингов пользователей и items
- Нелинейные взаимодействия между факторами

##### **Two-Tower архитектура**
- Отдельные энкодеры для пользователей и items
- Contrastive learning для обучения представлений

# *################ TODO ########################*
